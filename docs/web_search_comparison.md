# Web Search: Comparativa de Implementaciones

## üìä Resumen Ejecutivo

Brain ahora soporta **3 formas de b√∫squeda web**:

| M√©todo | Proveedor | Modelos | API Key | Costo | Calidad |
|--------|-----------|---------|---------|-------|---------|
| **DuckDuckGo** | Independiente | Todos | ‚ùå No | ‚úÖ Gratis | ‚≠ê‚≠ê‚≠ê Buena |
| **OpenAI Native** | OpenAI | gpt-4o-mini, gpt-4o, gpt-4-turbo | ‚úÖ S√≠ | üí∞ Medio | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| **Ollama** | Local | Todos (Ollama) | ‚ùå No | ‚úÖ Gratis | ‚≠ê‚≠ê B√°sica |

---

## 1Ô∏è‚É£ DuckDuckGo Search Tool (Implementado ‚úÖ)

### Descripci√≥n
Herramienta de b√∫squeda web standalone usando DuckDuckGo como motor.

### Caracter√≠sticas
- ‚úÖ **Gratuito** - Sin API keys
- ‚úÖ **Universal** - Funciona con cualquier LLM
- ‚úÖ **Independiente** - No depende del proveedor LLM
- ‚úÖ **Tool Registry** - Integrada en el sistema de herramientas

### Funcionamiento
```python
# El agente decide cu√°ndo usar la herramienta
tool_registry.execute("web_search", query="Python", max_results=5)

# Resultado:
{
  "success": true,
  "query": "Python",
  "results": [
    {"title": "...", "snippet": "...", "url": "..."},
    ...
  ]
}
```

### Uso
```bash
# Via Tool Agent
Usuario: "Busca informaci√≥n sobre Python"
‚Üí Tool Agent detecta necesidad de b√∫squeda
‚Üí Usa web_search tool
‚Üí Sintetiza respuesta con resultados

# Via API REST
POST /api/v1/tools/web_search/execute
{
  "query": "Python programming",
  "max_results": 5
}
```

### Pros
- ‚úÖ Sin costos
- ‚úÖ Sin l√≠mites (uso razonable)
- ‚úÖ Funciona con Ollama, OpenAI, Anthropic, etc.
- ‚úÖ Control total sobre resultados

### Contras
- ‚ö†Ô∏è Calidad inferior a Google/Bing
- ‚ö†Ô∏è Rate limiting ocasional
- ‚ö†Ô∏è El LLM debe parsear resultados manualmente
- ‚ö†Ô∏è No entiende contexto de b√∫squeda nativamente

### Cu√°ndo Usar
- Desarrollo local con Ollama
- Presupuesto limitado
- B√∫squedas ocasionales
- No requiere m√°xima calidad

---

## 2Ô∏è‚É£ OpenAI Native Web Search (Implementado ‚úÖ)

### Descripci√≥n
B√∫squeda web nativa integrada en OpenAI usando Bing como motor.

**Documentaci√≥n oficial**: https://platform.openai.com/docs/guides/tools?tool-type=web-search

### Caracter√≠sticas
- ‚úÖ **Nativo** - Integrado en el LLM
- ‚úÖ **Bing Search** - Motor de b√∫squeda de Microsoft
- ‚úÖ **Contextual** - El LLM entiende cu√°ndo buscar
- ‚úÖ **Autom√°tico** - Sin necesidad de parsear resultados

### Modelos Soportados
- `gpt-4o-mini` ‚≠ê Recomendado (econ√≥mico)
- `gpt-4o`
- `gpt-4-turbo`

### Funcionamiento
```python
# El LLM decide autom√°ticamente cu√°ndo buscar
messages = [
    {"role": "user", "content": "¬øCu√°l es el precio del Bitcoin hoy?"}
]

# Se habilita web search en la llamada
payload = {
    "model": "gpt-4o-mini",
    "messages": messages,
    "tools": [{"type": "web_search"}]
}

# El LLM:
# 1. Detecta que necesita info actualizada
# 2. Busca autom√°ticamente en Bing
# 3. Integra resultados en su respuesta
```

### Uso

#### Via Agente Especializado (Nuevo)
```bash
# Desde la GUI
Chain: openai_web_search
Query: "√öltimas noticias de IA"

# El agente usa web search nativo autom√°ticamente
```

#### Via API
```bash
curl -X POST http://localhost:8000/api/v1/engine/execute \
  -H "Content-Type: application/json" \
  -d '{
    "chain_id": "openai_web_search",
    "input": {
      "message": "¬øCu√°l es el precio del Bitcoin?"
    }
  }'
```

#### Program√°ticamente
```python
from engine.chains.native_web_search import call_llm_with_web_search

result = await call_llm_with_web_search(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Latest AI news"}],
    api_key="sk-...",
    temperature=0.7
)

# Resultado incluye b√∫squedas realizadas
{
  "success": true,
  "content": "...",
  "web_searches": [
    {"id": "search_123", "query": {...}}
  ],
  "usage": {"total_tokens": 1234}
}
```

### Costos (Enero 2024)

| Modelo | Input (1M tokens) | Output (1M tokens) |
|--------|-------------------|-------------------|
| gpt-4o-mini | $0.15 | $0.60 |
| gpt-4o | $2.50 | $10.00 |
| gpt-4-turbo | $10.00 | $30.00 |

**Nota**: Web search incrementa el uso de tokens (b√∫squedas + resultados).

Ejemplo:
- Query: "Precio Bitcoin" (~10 tokens)
- B√∫squeda + resultados: ~500 tokens adicionales
- Respuesta: ~100 tokens
- **Total**: ~610 tokens ‚âà $0.0001 con gpt-4o-mini

### Pros
- ‚úÖ M√°xima calidad de resultados (Bing)
- ‚úÖ Integraci√≥n nativa en el LLM
- ‚úÖ Contexto autom√°tico
- ‚úÖ No necesita parseo manual
- ‚úÖ Citas y fuentes incluidas

### Contras
- ‚ö†Ô∏è Requiere API key de OpenAI (costo)
- ‚ö†Ô∏è Solo modelos espec√≠ficos
- ‚ö†Ô∏è Incrementa uso de tokens
- ‚ö†Ô∏è Dependencia de OpenAI

### Cu√°ndo Usar
- **Producci√≥n** con presupuesto
- Requiere **m√°xima calidad**
- **Noticias** y datos en tiempo real
- Usuario final espera **mejor respuesta**

---

## 3Ô∏è‚É£ Ollama (Local) - Sin Web Search Nativo ‚ùå

### Estado Actual
**Ollama NO tiene b√∫squeda web nativa integrada.**

### ¬øPor qu√©?
Ollama es un **runtime local** para ejecutar LLMs open-source:
- Llama 3.2, Mistral, Phi, etc.
- Se ejecuta en tu hardware
- Sin conexi√≥n a internet requerida
- No tiene backend de b√∫squeda

### Alternativas para Ollama

#### Opci√≥n 1: DuckDuckGo Tool (‚úÖ Recomendado)
```python
# Usar la herramienta DuckDuckGo con Ollama
chain: tool_agent
provider: ollama
model: llama3.2

# El tool_agent puede usar web_search con cualquier LLM
```

**Ventajas:**
- ‚úÖ Funciona con cualquier modelo de Ollama
- ‚úÖ Completamente local + b√∫squeda web
- ‚úÖ Sin costos adicionales

#### Opci√≥n 2: Browser Agent
```python
# Usar el Browser Agent para b√∫squedas
chain: browser_agent
provider: ollama

# Navega a Google/DuckDuckGo y extrae resultados
```

**Ventajas:**
- ‚úÖ Visual (puedes ver qu√© busca)
- ‚úÖ M√°s flexible
- ‚ö†Ô∏è M√°s lento

#### Opci√≥n 3: Plugin MCP (Futuro)
Model Context Protocol puede agregar capacidades externas a Ollama:
```json
{
  "mcp_tool": "web_search",
  "provider": "duckduckgo"
}
```

### Comparativa Ollama vs OpenAI para Web Search

| Aspecto | Ollama + DuckDuckGo | OpenAI Native |
|---------|-------------------|---------------|
| Costo | ‚úÖ Gratis | üí∞ $0.0001/query |
| Privacidad | ‚úÖ Local | ‚ö†Ô∏è Cloud |
| Calidad b√∫squeda | ‚≠ê‚≠ê‚≠ê Buena | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| Velocidad | ‚ö†Ô∏è Media | ‚úÖ R√°pida |
| Setup | ‚ö†Ô∏è Complejo | ‚úÖ Simple |
| Integraci√≥n | ‚ö†Ô∏è Manual | ‚úÖ Nativa |

---

## üìã Gu√≠a de Selecci√≥n

### Desarrollo Local
```
üéØ DuckDuckGo + Ollama
- Sin costos
- Privacidad completa
- Ideal para desarrollo
```

### Producci√≥n - Presupuesto Limitado
```
üéØ DuckDuckGo + OpenAI/Anthropic
- Usa DuckDuckGo para b√∫squedas
- LLM premium para razonamiento
- Balance costo/calidad
```

### Producci√≥n - M√°xima Calidad
```
üéØ OpenAI Native Web Search
- gpt-4o-mini para econom√≠a
- gpt-4o para calidad premium
- Integraci√≥n nativa
```

### Caso H√≠brido
```
üéØ Ambos m√©todos
- DuckDuckGo para b√∫squedas simples
- OpenAI Native para consultas cr√≠ticas
- Decisi√≥n din√°mica basada en contexto
```

---

## üîß Configuraci√≥n en Brain

### Habilitar DuckDuckGo (Ya configurado ‚úÖ)
```python
# Autom√°tico - disponible para todos los agentes
tool_registry.execute("web_search", query="...")
```

### Habilitar OpenAI Native
```bash
# 1. Configurar provider en Strapi
GUI ‚Üí Settings ‚Üí LLM Providers
- Type: openai
- Base URL: https://api.openai.com/v1
- API Key: sk-...
- Model: gpt-4o-mini

# 2. Usar el agente especializado
Chain: openai_web_search
```

### Habilitar web_search en llamadas generales
```python
# En llm_utils.py (ya implementado)
await call_llm(
    llm_url="https://api.openai.com/v1",
    model="gpt-4o-mini",
    messages=[...],
    provider_type="openai",
    api_key="sk-...",
    enable_web_search=True  # ‚Üê Nuevo par√°metro
)
```

---

## üìä Benchmarks

### Calidad de Resultados (1-10)

| Query | DuckDuckGo | OpenAI Native |
|-------|-----------|---------------|
| "Precio Bitcoin" | 7 | 10 |
| "Noticias IA" | 6 | 9 |
| "Tutorial Python" | 8 | 9 |
| "Clima Madrid" | 7 | 10 |
| "Documentaci√≥n t√©cnica" | 8 | 8 |

### Velocidad (segundos)

| M√©todo | Primera b√∫squeda | Cach√© |
|--------|------------------|-------|
| DuckDuckGo | 2-3s | N/A |
| OpenAI Native | 3-5s | N/A |
| Browser Agent | 5-10s | N/A |

---

## üöÄ Roadmap

### Corto Plazo
- [ ] Cach√© Redis para DuckDuckGo
- [ ] M√©tricas de uso por m√©todo
- [ ] Dashboard de comparaci√≥n

### Medio Plazo
- [ ] Fallback autom√°tico (OpenAI ‚Üí DuckDuckGo)
- [ ] Selecci√≥n din√°mica basada en query
- [ ] Soporte para Tavily API

### Largo Plazo
- [ ] Plugin MCP para Ollama
- [ ] √çndice local de b√∫squedas frecuentes
- [ ] Integraci√≥n con RAG para cach√© inteligente

---

## üìö Referencias

- [OpenAI Web Search Docs](https://platform.openai.com/docs/guides/tools?tool-type=web-search)
- [DuckDuckGo Search API](https://github.com/deedy5/duckduckgo_search)
- [Ollama Documentation](https://ollama.ai/docs)
- [Brain Architecture](./architecture.md)

---

**Actualizado**: 2024-01-19
**Versi√≥n**: 1.0.0
